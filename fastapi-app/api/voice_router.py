# /api/voice_router.py

import asyncio
import json
import os
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from google.oauth2 import service_account
from google.cloud.speech_v1.services import speech
from google.cloud.speech_v1.types import RecognitionConfig, StreamingRecognitionConfig, StreamingRecognizeRequest
import google.generativeai as genai

router = APIRouter()

CREDENTIALS_PATH = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
google_credentials = None
if CREDENTIALS_PATH:
    try:
        google_credentials = service_account.Credentials.from_service_account_file(CREDENTIALS_PATH)
        print("âœ… Speech-to-Text ì¸ì¦ ì„±ê³µ!")
    except Exception as e:
        print(f"ğŸš¨ ì¸ì¦ íŒŒì¼ ì˜¤ë¥˜: {e}")
else:
    print("ğŸš¨ GOOGLE_APPLICATION_CREDENTIALS ë³€ìˆ˜ ì„¤ì • ì—†ìŒ.")

try:
    gemini_model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    print(f"ğŸš¨ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    gemini_model = None

async def send_error_message(ws: WebSocket, text: str):
    try: await ws.send_text(json.dumps({"type": "error", "text": text}))
    except Exception: pass

async def generate_and_send_gemini_response(ws: WebSocket, user_text: str):
    if not gemini_model:
        await send_error_message(ws, "Gemini APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    try:
        print(f"ğŸš€ Calling Gemini API with text: {user_text}")
        response = await asyncio.to_thread(gemini_model.generate_content, user_text)
        bot_response_text = response.text.strip()
        print(f"ğŸ¤– Gemini API Response: {bot_response_text}")
        response_message = {"type": "botResponse", "userText": user_text, "botResponseText": bot_response_text}
        await ws.send_text(json.dumps(response_message))
    except Exception as e:
        print(f"Error during Gemini processing: {e}")
        await send_error_message(ws, "ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# [êµ¬ì¡° ë³€ê²½] ì´ì œ ì´ í•¨ìˆ˜ëŠ” 'while True' ì—†ì´ í•œ ë²ˆì˜ ëŒ€í™”ë§Œ ì²˜ë¦¬í•˜ê³  ì¢…ë£Œë©ë‹ˆë‹¤.
async def transcribe_audio_stream(websocket: WebSocket, audio_queue: asyncio.Queue, stop_event: asyncio.Event):
    if not google_credentials:
        await send_error_message(websocket, "ì„œë²„ì— Google Cloud ì¸ì¦ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    speech_client = speech.SpeechAsyncClient(credentials=google_credentials)

    async def audio_generator():
        streaming_config = StreamingRecognitionConfig(
            config=RecognitionConfig(encoding=RecognitionConfig.AudioEncoding.WEBM_OPUS, sample_rate_hertz=48000, language_code="ko-KR"),
            interim_results=True
        )
        yield StreamingRecognizeRequest(streaming_config=streaming_config)
        
        while not stop_event.is_set():
            try:
                data = await asyncio.wait_for(audio_queue.get(), timeout=0.1)
                yield StreamingRecognizeRequest(audio_content=data)
            except asyncio.TimeoutError:
                continue
            except asyncio.CancelledError:
                break

    try:
        requests = audio_generator()
        stream = await speech_client.streaming_recognize(requests=requests)
        async for response in stream:
            if not response.results or not response.results[0].alternatives: continue
            transcript = response.results[0].alternatives[0].transcript
            if not response.results[0].is_final:
                await websocket.send_text(json.dumps({"type": "transcript", "text": transcript}))
            else:
                await generate_and_send_gemini_response(websocket, transcript)
    except Exception as e:
        print(f"Error in transcriber: {e}")
    finally:
        print("âœ… Transcription stream finished for one utterance.")

# [êµ¬ì¡° ë³€ê²½] ì´ í•¨ìˆ˜ê°€ ì „ì²´ íë¦„ì„ ì œì–´í•©ë‹ˆë‹¤.
@router.websocket("/voice-chat")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("âœ… Voice chat client connected and ready.")

    try:
        # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ê°€ ì˜¬ ë•Œê¹Œì§€ ê³„ì† ëŒ€ê¸°
        while True:
            message = await websocket.receive()
            data = json.loads(message.get("text", "{}"))

            if data.get("type") == "text_input":
                await generate_and_send_gemini_response(websocket, data.get("text"))

            # "ìŒì„± ì‹œì‘" ì‹ í˜¸ë¥¼ ë°›ìœ¼ë©´, ìƒˆë¡œìš´ ëŒ€í™” í•œ í„´ì„ ì‹œì‘
            elif data.get("type") == "start_speech":
                print("ğŸ¤... Starting new utterance ...ğŸ¤")
                audio_queue = asyncio.Queue()
                stop_event = asyncio.Event()
                
                transcribe_task = asyncio.create_task(
                    transcribe_audio_stream(websocket, audio_queue, stop_event)
                )

                # ìŒì„± ë°ì´í„° ë° ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹  ë£¨í”„
                while not stop_event.is_set():
                    message = await websocket.receive()
                    if "bytes" in message:
                        await audio_queue.put(message["bytes"])
                    elif "text" in message:
                        data = json.loads(message["text"])
                        if data.get("type") == "end_of_speech":
                            stop_event.set()
                
                await transcribe_task
                print("--- Conversation turn finished, waiting for next start signal. ---")

    except WebSocketDisconnect:
        print("ğŸ”Œ Voice chat client disconnected.")
    except Exception as e:
        print(f"An unexpected error occurred in main loop: {e}")