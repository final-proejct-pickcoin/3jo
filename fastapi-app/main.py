from fastapi import FastAPI, WebSocket, Request, WebSocketDisconnect, status, Query, Form
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse, JSONResponse, RedirectResponse
from fastapi.middleware.cors import CORSMiddleware

import jwt
from passlib.context import CryptContext
from dotenv import load_dotenv
import os
import redis
from utils.user_manager import ConnectionManager
from service.alert_manager import AlertManager

from passlib.context import CryptContext
from utils.jwt_helper import create_access_token, verify_token
from dotenv import load_dotenv
from utils.user_manager import ConnectionManager
from typing import Dict

from json import dumps
import json

# ë¼ìš°í„°ë“¤
from api.news_router import router as news_router
from api.auth import router as auth_router
from api.admin_user import router as admin_user_router
from api.admin import router as admin_router
from api.inquiry import router as inq_router
from api.chat import router as ws_router
from api.bithumb_api import router as bithumb_router, realtime_ws
from api.elasticsearch import create_indices_if_not_exist, wait_for_es, create_kibana_index_pattern
from api.ml_router import router as ml_router

# ìŠ¤ì¼€ì¤„ë§ ê´€ë ¨ [news schedule] í¬ë¡¤ë§ ì£¼ê¸° ì„¤ì •
from apscheduler.schedulers.background import BackgroundScheduler
from service.news_service import crawl_and_save
from datetime import datetime
from repository.news_repository import delete_news_older_than, trim_news_by_count

# ìŒì„± AI ê´€ë ¨ ëª¨ë“ˆ
import google.generativeai as genai
from api.voice_router import router as voice_ai_router
from google.cloud import speech

from db.mysql import ping
from fastapi import APIRouter

import threading
import time
import asyncio
from zoneinfo import ZoneInfo

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="í†µí•© ê°€ìƒí™”í í”Œë«í¼ API",
    description="ì±„íŒ…, ë‰´ìŠ¤, ìŒì„± AI, ê°€ìƒí™”í ê°€ê²© ì˜ˆì¸¡ì´ í†µí•©ëœ í”Œë«í¼",
    version="1.0"
)

# --- ê¸°ë³¸ ì„¤ì •ë“¤ ---
SECRET_KEY = os.getenv("SECRET_KEY")
ALGORITHM = os.getenv("ALGORITHM", "HS256")
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", 30))
host = 'mysql'

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
templates = Jinja2Templates(directory="templates")

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    print("ê²½ê³ : .env íŒŒì¼ì— GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

#ë¹—ì¸+ì œë¯¸ë‚˜ì´ ì—°ë™ // ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •, ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ ì„í¬íŠ¸ ê°€ëŠ¥ // __all__ = ["redis_client"]
from api.ai_coin_connect import redis_client
# Redis ì„¤ì • // docker-compose.ymlì˜ ì„œë¹„ìŠ¤ëª… redis
redis_client = redis.Redis(host='redis', port=6379, db=0, decode_responses=True)

# --- í—¬ìŠ¤ì²´í¬ ë¼ìš°í„° ---
health = APIRouter()

# --- DB Healthcheck (ì„ì‹œ) ---
@health.get("/health/db")
def health_db():
    """DB ì—°ê²° ìƒíƒœ í™•ì¸ìš©"""
    return {"db_ok": ping()}

@app.get("/api/ping")
def api_ping():
    return {"pong": True}

# --- CORS ì„¤ì • ---
origins = [
    "http://localhost:3000",
    "http://localhost:8080", 
    "http://localhost",
    "http://127.0.0.1:3000",
    "http://127.0.0.1:8080",
    "http://127.0.0.1"
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

# ===== ë¼ìš°í„° ë“±ë¡ =====
app.include_router(health) # DB Health ë¼ìš°í„°
app.include_router(news_router) # ë‰´ìŠ¤ í¬ë¡¤ë§ ë¼ìš°í„°
app.include_router(auth_router) # ë¡œê·¸ì¸, ë¡œê·¸ì•„ì›ƒ, íšŒì›ê°€ì… ë¼ìš°í„°
app.include_router(admin_user_router) # admin_user ë¡œê·¸ ë¼ìš°í„°
app.include_router(admin_router) # ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ë°›ì•„ì˜¬ ë¼ìš°í„°
app.include_router(inq_router) # ë¬¸ì˜ ë¼ìš°í„°
app.include_router(ws_router) # ì±„íŒ… ì›¹ì†Œì¼“ ë¼ìš°í„°
app.include_router(bithumb_router) # ë¹—ì¸ API ë¼ìš°í„°
app.include_router(voice_ai_router, prefix="/api") # ìŒì„± AI ë¼ìš°í„°
app.include_router(ml_router) # ML ë¼ìš°í„° 

# ===== ì›¹ì†Œì¼“ í•¸ë“¤ëŸ¬ë“¤ =====

manager = ConnectionManager()
alert_manager = AlertManager()

#websocket_realtime_endpoint()
@app.websocket("/ws/realtime")
async def websocket_endpoint(websocket: WebSocket):
    """ë¹—ì¸ ì‹¤ì‹œê°„ ë°ì´í„° ì›¹ì†Œì¼“"""
    await realtime_ws(websocket)

#websocket_chat_endpoint()
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, token: str = Query(...), room: str = Query("default")):
    """ì±„íŒ… ì›¹ì†Œì¼“ í•¸ë“¤ëŸ¬"""
    # token = websocket.query_params.get("token")
    # 1. JWT í† í° ê²€ì¦
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        username = payload.get("sub")
        print("ğŸŸ¢ JWT payload:", payload)
        if username is None:
            raise ValueError("No username in token")
    except Exception as e:
        print("âŒ JWT ê²€ì¦ ì‹¤íŒ¨:", e)
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        return

    # 2. ì±„íŒ…ë°© key ì„¤ì •
    chat_key = f"chatlog:{room}"

    # âœ… ë¨¼ì € websocket ì—°ê²° ìˆ˜ë½
    await manager.connect(websocket, room, username)
    
    # 3. ì—°ê²° ì¦‰ì‹œ, ìµœê·¼ ë©”ì„¸ì§€ 100ê°œ ë³´ë‚´ê¸°
    recent_msgs = redis_client.lrange(chat_key, -100, -1)
    for msg in recent_msgs:
        await websocket.send_text(msg)

    # 4. ë¸Œë¡œë“œìºìŠ¤íŠ¸ ë° ë©”ì„¸ì§€ ê¸°ë¡    
    await manager.broadcast(f"âœ… {username}ë‹˜ì´ [{room}] ì±„íŒ…ë°©ì— ì…ì¥í–ˆìŠµë‹ˆë‹¤.", room)

    try:
        while True:
            data = await websocket.receive_text()

            msg_data = {
                "sender": username,
                "room": room,
                "message": data
            }
            redis_client.rpush(chat_key, dumps(msg_data))
            # í•œ ë°©ì— 500ê°œë§Œ ìœ ì§€
            redis_client.ltrim(chat_key, -500, -1)
            await manager.broadcast(dumps(msg_data), room)  # ë°©ì— ë¿Œë¦¼

            # ì˜ˆ: dm between userA and userB
            members = room.split("-")
            for member in members:
                if member != username:  # ë°›ì€ ì‚¬ëŒ (ë‚˜ ì œì™¸)
                    await alert_manager.send_alert(to_user_id=member, from_user_id=username, message=data)

    except WebSocketDisconnect:
        manager.disconnect(websocket, room, username)
        await manager.broadcast(f"âŒ {username}ë‹˜ì´ í‡´ì¥í–ˆìŠµë‹ˆë‹¤.", room)

# ë‹¤ë¥¸ ê³³ì— ìˆì„ ë•Œ ì•ŒëŒë°›ê¸°
@app.websocket("/ws/alert")
async def alert_listener(websocket: WebSocket, token: str = Query(...)):
    """ì•Œë¦¼ ìˆ˜ì‹  ì›¹ì†Œì¼“"""
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        user_id = payload.get("sub")
    except:
        await websocket.close()
        return

    await alert_manager.connect(websocket, user_id)

    try:
        while True:
            await websocket.receive_text()  # ì–´ë–¤ ì…ë ¥ë„ ì•ˆ ë°›ì§€ë§Œ ëŠê¸°ì§€ ì•Šê²Œ
    except WebSocketDisconnect:
        alert_manager.disconnect(websocket, user_id)

# ===== ì›¹ í˜ì´ì§€ë“¤ =====
#ì±„íŒ…
@app.get("/", response_class=HTMLResponse)
async def get_root(request: Request):
    """ë©”ì¸ ì±„íŒ… í˜ì´ì§€"""
    return templates.TemplateResponse("chat.html", {"request": request})
#ë¡œê·¸ì¸
@app.get("/login", response_class=HTMLResponse)
async def login_page(request: Request):
    return templates.TemplateResponse("login.html", {"request": request})

@app.get("/chat", response_class=HTMLResponse)
async def chat_page(request: Request):
    return templates.TemplateResponse("chat.html", {"request": request})

# ===== Elasticsearch ì´ˆê¸°í™” =====
# í™˜ê²½ë³€ìˆ˜:
#   ES_ENABLED=0        â†’ ES ì´ˆê¸°í™” ìŠ¤í‚µ (ê¸°ë³¸ 1)
#   ES_MAX_WAIT=120     â†’ ìµœëŒ€ ëŒ€ê¸° ì´ˆ(ê¸°ë³¸ 120)
#   ES_WAIT_INTERVAL=3  â†’ ì¬ì‹œë„ ê°„ê²© ì´ˆ(ê¸°ë³¸ 3)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_search_background():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ Elasticsearch ì´ˆê¸°í™”"""
    try:
        if os.getenv("ES_ENABLED", "1") != "1":
            print("[es] disabled by ES_ENABLED=0")
            return

        max_wait = int(os.getenv("ES_MAX_WAIT", "120"))
        interval = int(os.getenv("ES_WAIT_INTERVAL", "3"))

        # 1) ESê°€ ì‘ë‹µí•  ë•Œê¹Œì§€ wait_for_esë¥¼ ì§§ê²Œ ì—¬ëŸ¬ ë²ˆ ì‹œë„
        print(f"[es] waiting for ES (max_wait={max_wait}s, interval={interval}s)â€¦")
        start = time.time()
        while time.time() - start < max_wait:
            try:
                asyncio.run(wait_for_es(timeout=interval, interval=1))
                print("[es] wait_for_es OK")
                break
            except Exception as e:
                print(f"[es] wait_for_es retry: {e}")
                time.sleep(interval)

        # 2) ì¸ë±ìŠ¤ ìƒì„± (ì—¬ëŸ¬ ë²ˆ ì¬ì‹œë„)
        deadline = time.time() + max_wait
        while time.time() < deadline:
            try:
                create_indices_if_not_exist()
                print("[es] indices ready")
                return
            except Exception as e:
                print(f"[es] create_indices retry in {interval}s: {type(e).__name__} - {e}")
                time.sleep(interval)

        print(f"[es] not ready within {max_wait}s; skip initializing indices (app continues)")
    except Exception as e:
        print(f"[es] init_search_background failed: {type(e).__name__} - {e}")

# ===== ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • =====

# 1) ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ (ì„œìš¸ íƒ€ì„ì¡´)
scheduler = BackgroundScheduler(
    timezone="Asia/Seoul",
    job_defaults={
        "coalesce": True,           # ë°€ë¦° ì‹¤í–‰ì€ 1íšŒë¡œ í•©ì¹˜ê¸°
        "misfire_grace_time": 3600  # 1ì‹œê°„ ì´ë‚´ ë†“ì¹œ ì‹¤í–‰ í—ˆìš©
    }
)

def job_news_refresh():
    """
    8ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰ë  ì‹¤ì œ ì‘ì—… í•¨ìˆ˜.
    ë‚´ë¶€ì—ì„œ í¬ë¡¤ë§í•˜ê³  save_news()ë¡œ ì—…ì„œíŠ¸ê¹Œì§€ ìˆ˜í–‰.
    """
    try:
        print(f"[scheduler] news refresh start {datetime.now()}")
        saved = crawl_and_save(limit=20) or 0
        print(f"[scheduler] news refresh saved {saved} rows")

        # âœ… ì €ì¥ì´ 1ê±´ ì´ìƒì¼ ë•Œë§Œ ì •ë¦¬ ìˆ˜í–‰ (í…Œì´ë¸”ì´ ì ê¹ ë¹„ëŠ” í˜„ìƒ ë°©ì§€)
        if saved > 0:
            deleted_by_days = delete_news_older_than(days=2)
            print(f"[scheduler] cleanup(days) deleted {deleted_by_days} rows")

            deleted_by_cap = trim_news_by_count(max_rows=300)
            print(f"[scheduler] cleanup(cap) deleted {deleted_by_cap} rows")
        else:
            print("[scheduler] skip cleanup (no new rows)")

    except Exception:
        import traceback
        print("[scheduler] ERROR in job_news_refresh")
        traceback.print_exc()

# ===== ì•± ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ =====
# 2) ì•± ì‹œì‘ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ + ES ì´ˆê¸°í™”(ë¹„ì°¨ë‹¨)
@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ì‹œ ì´ˆê¸°í™” ì‘ì—…ë“¤"""
    try:
        print("ğŸš€ í†µí•© ê°€ìƒí™”í í”Œë«í¼ ì‹œì‘ ì¤‘...")
        
        # âœ… ES ì´ˆê¸°í™”ëŠ” ì•±ì„ ë§‰ì§€ ì•Šë„ë¡ "ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ"ì—ì„œ ìˆ˜í–‰
        threading.Thread(target=init_search_background, daemon=True).start()

        # âœ… Kibana ë°ì´í„°ë·° ìë™ ìƒì„± (ë¹„ì°¨ë‹¨)
        def _init_kibana():
            try:
                asyncio.run(create_kibana_index_pattern())
            except Exception as e:
                print(f"[kibana] init failed: {e}")
        threading.Thread(target=_init_kibana, daemon=True).start()

        # âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ë™
        if not scheduler.running:
            scheduler.start()

        # ğŸ“ ì£¼ê¸° ì‘ì—… ë“±ë¡ (8ì‹œê°„ë§ˆë‹¤ ë‰´ìŠ¤ í¬ë¡¤ë§)
        if scheduler.get_job("news_refresh_hourly") is None:   # â† ì¤‘ë³µë“±ë¡ ë°©ì§€
            scheduler.add_job(
                job_news_refresh,
                trigger="interval",
                hours=8,                            # â† 8ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
                id="news_refresh_hourly",
                replace_existing=True,
            )

        # ğŸš€ ì„œë²„ ê¸°ë™ ì§í›„ 1íšŒ ì¦‰ì‹œ ì‹¤í–‰ â€” ì´ˆê¸° ë°ì´í„° ì±„ìš°ê¸° ìš©
        if scheduler.get_job("news_refresh_boot") is None:  # â† ì¤‘ë³µë“±ë¡ ë°©ì§€
            scheduler.add_job(
                job_news_refresh,
                trigger="date",         # â† ë‹¨ë°œì„± ì‹¤í–‰ì„ ìœ„í•´ ë°˜ë“œì‹œ í•„ìš”
                run_date=datetime.now(ZoneInfo("Asia/Seoul")),      # â† íƒ€ì„ì¡´ í¬í•¨
                id="news_refresh_boot",
                replace_existing=True
            )

        print("âœ… í†µí•© í”Œë«í¼ ì‹œì‘ ì™„ë£Œ!")
        print("ğŸ“Š ì œê³µ ì„œë¹„ìŠ¤:")
        print("  - ì‹¤ì‹œê°„ ì±„íŒ… & ì•Œë¦¼")
        print("  - ë‰´ìŠ¤ í¬ë¡¤ë§ & ê²€ìƒ‰ (hourly news refresh)")  
        print("  - ìŒì„± AI ì±—ë´‡")
        print("  - ğŸ¤– ML ê°€ê²© ì˜ˆì¸¡ (ìƒˆë¡œ ì¶”ê°€)")
        print("  - ì‹¤ì‹œê°„ ê±°ë˜ì†Œ ë°ì´í„°")
        
    except Exception:
        import traceback
        print("[startup] failed")
        traceback.print_exc()

# 3) ì•± ì¢…ë£Œ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì •ë¦¬
@app.on_event("shutdown")
def shutdown_event():
    """ì•± ì¢…ë£Œì‹œ ì •ë¦¬ ì‘ì—…"""
    try:
        scheduler.shutdown(wait=False)
        print("[scheduler] stopped")
        print("ğŸ‘‹ í†µí•© í”Œë«í¼ ì¢…ë£Œ")
    except Exception:
        pass

# ===== í†µí•© í—¬ìŠ¤ì²´í¬ =====

@app.get("/health", tags=["System"])
async def integrated_health_check():
    """í†µí•© ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    # ML ëª¨ë¸ ìƒíƒœ í™•ì¸
    ml_models_available = False
    ml_models_count = 0
    try:
        if os.path.exists("ml/models"):
            for item in os.listdir("ml/models"):
                model_dir = os.path.join("ml/models", item)
                if os.path.isdir(model_dir) and os.path.exists(os.path.join(model_dir, "model.pt")):
                    ml_models_count += 1
        ml_models_available = ml_models_count > 0
    except:
        pass
    
    # Redis ì—°ê²° ìƒíƒœ í™•ì¸
    redis_status = False
    try:
        redis_client.ping()
        redis_status = True
    except:
        pass
    
    # DB ì—°ê²° ìƒíƒœ í™•ì¸
    db_status = ping()
    
    return {
        "status": "healthy" if all([redis_status, db_status, ml_models_available]) else "degraded",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "database": db_status,
            "redis": redis_status,
            "ml_models": {
                "available": ml_models_available,
                "count": ml_models_count
            }
        },
        "services": {
            "chat": True,
            "news": True,
            "voice_ai": True,
            "ml_prediction": ml_models_available,
            "realtime_trading": True
        }
    }

# ===== í†µí•© API ì •ë³´ =====

@app.get("/api/info", tags=["System"])
async def get_api_info():
    """í†µí•© API ì„œë¹„ìŠ¤ ì •ë³´"""
    # ML ëª¨ë¸ ê°œìˆ˜ í™•ì¸
    ml_models_count = 0
    try:
        if os.path.exists("ml/models"):
            for item in os.listdir("ml/models"):
                model_dir = os.path.join("ml/models", item)
                if os.path.isdir(model_dir) and os.path.exists(os.path.join(model_dir, "model.pt")):
                    ml_models_count += 1
    except:
        pass
    
    return {
        "platform_name": "í†µí•© ê°€ìƒí™”í í”Œë«í¼",
        "version": "3.0",
        "services": {
            "chat": {
                "description": "ì‹¤ì‹œê°„ ì±„íŒ… ë° ì•Œë¦¼ ì‹œìŠ¤í…œ",
                "websocket": "/ws",
                "features": ["JWT ì¸ì¦", "ë£¸ë³„ ì±„íŒ…", "ì‹¤ì‹œê°„ ì•Œë¦¼"]
            },
            "news": {
                "description": "ê°€ìƒí™”í ë‰´ìŠ¤ í¬ë¡¤ë§ ë° ê²€ìƒ‰",
                "endpoints": ["/api/news/*"],
                "features": ["ìë™ í¬ë¡¤ë§", "Elasticsearch ê²€ìƒ‰", "ê°ì„±ë¶„ì„"]
            },
            "voice_ai": {
                "description": "ìŒì„± ì¸ì‹ AI ì±—ë´‡",
                "websocket": "/api/voice-chat", 
                "features": ["Google Speech-to-Text", "Gemini AI", "ì‹¤ì‹œê°„ ì½”ì¸ ì •ë³´ ì—°ë™"]
            },
            "ml_prediction": {
                "description": "ê°œë³„ ì½”ì¸ë³„ LSTM ê°€ê²© ì˜ˆì¸¡",
                "endpoints": ["/ml/*"],
                "trained_models": ml_models_count,
                "features": ["ê°œë³„ ì½”ì¸ ëª¨ë¸", "ê°ì„±ë¶„ì„ í†µí•©", "ê¸°ìˆ ì  ì§€í‘œ í™œìš©"]
            },
            "trading_data": {
                "description": "ì‹¤ì‹œê°„ ê±°ë˜ì†Œ ë°ì´í„°",
                "endpoints": ["/api/*"],
                "websocket": "/ws/realtime",
                "features": ["ë¹—ì¸ API ì—°ë™", "ì‹¤ì‹œê°„ ì‹œì„¸", "WebSocket ìŠ¤íŠ¸ë¦¬ë°"]
            }
        },
        "integrations": {
            "databases": ["MySQL", "Redis", "Elasticsearch"],
            "external_apis": ["ë¹—ì¸", "CoinGecko", "Google Cloud", "Gemini AI"],
            "real_time": ["WebSocket", "ì‹¤ì‹œê°„ ì•Œë¦¼", "ë¼ì´ë¸Œ ì±„íŒ…"]
        },
        "endpoints_summary": {
            "system": ["/health", "/api/ping", "/api/info"],
            "auth": ["/login", "/register", "/api/auth/*"],
            "chat": ["/ws", "/ws/alert", "/chat"],
            "news": ["/api/news/*", "/debug/crawl-now"],
            "ml": ["/ml/predict", "/ml/batch_predict", "/ml/available_coins"],
            "trading": ["/api/coins", "/api/ticker/*", "/ws/realtime"],
            "voice": ["/api/voice-chat", "/api/supported-coins"],
            "admin": ["/api/admin/*", "/api/admin-user/*"]
        }
    }

# ===== ë””ë²„ê¹… ì—”ë“œí¬ì¸íŠ¸ë“¤ =====

# Redis ë””ë²„ê¹…
@app.get("/api/debug/redis-keys", tags=["Debug"])
async def debug_redis_keys():
    """Redisì— ì €ì¥ëœ ticker í‚¤ë“¤ í™•ì¸ (ë””ë²„ê¹…ìš©)"""
    try:
        keys = redis_client.keys("ticker:*")
        result = {}
        for key in keys:
            data = redis_client.get(key)
            if data:
                parsed = json.loads(data)
                result[key] = {
                    "closing_price": parsed.get("closing_price", "N/A"),
                    "symbol": parsed.get("symbol", "N/A"),
                    "timestamp": parsed.get("date", "N/A")
                }
        return {
            "total_keys": len(keys),
            "keys": result
        }
    except Exception as e:
        return {"error": str(e)}

@app.get("/api/debug/test-voice-price/{symbol}", tags=["Debug"])  
async def test_voice_price(symbol: str):
    """ìŒì„± AIì—ì„œ ì‚¬ìš©í•˜ëŠ” ê°€ê²© ì¡°íšŒ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    from api.voice_router import get_realtime_price
    
    result = get_realtime_price(symbol.upper())
    
    return {
        "symbol": symbol,
        "result": result,
        "has_data": result is not None,
        "closing_price": result.get('closing_price') if result else None
    }

# --- ìŠ¤ì¼€ì¤„ëŸ¬ í—¬ìŠ¤ì²´í¬ (ë¬´í•œ ë¡œë”© ë°©ì§€ ë²„ì „) ---
@app.get("/api/debug/scheduler", tags=["Debug"])
def scheduler_status():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸"""
    try:
        # ì•ˆì „í•˜ê²Œ ìƒíƒœ ì½ê¸°
        state = getattr(scheduler, "state", None)
        running = bool(getattr(scheduler, "running", False))

        jobs_info = []
        for j in scheduler.get_jobs():
            nrt = None
            try:
                nrt = j.next_run_time.isoformat() if j.next_run_time else None
            except Exception:
                nrt = str(j.next_run_time)
            jobs_info.append({"id": j.id, "next_run_time": nrt})

        return {
            "running": running,
            "state": state,
            "jobs": jobs_info
        }
    except Exception as e:
        # ì–´ë–¤ ì—ëŸ¬ì—¬ë„ ì¦‰ì‹œ JSON 500 ë°˜í™˜ -> ë¬´í•œë¡œë”© ë°©ì§€
        return JSONResponse({"error": str(e)}, status_code=500)

# í…ŒìŠ¤íŠ¸ìš©: ìˆ˜ë™ìœ¼ë¡œ í•œ ë²ˆ í¬ë¡¤ë§í•´ì„œ DBì— ì €ì¥ _news_services
@app.post("/debug/crawl-now", tags=["Debug"])
def debug_crawl_now(limit: int = 20):
    saved = crawl_and_save(limit=limit)
    return {"saved": saved}


'''
if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ í†µí•© ê°€ìƒí™”í í”Œë«í¼ ì„œë²„ ì‹œì‘ ì¤‘...")
    print("ğŸ”— ì„œë¹„ìŠ¤ í¬íŠ¸: 8000")
    print("ğŸ“¡ WebSocket ì§€ì›: ì±„íŒ…, ì‹¤ì‹œê°„ ë°ì´í„°, ìŒì„± AI")
    print("ğŸ¤– AI ê¸°ëŠ¥: ê°€ê²© ì˜ˆì¸¡, ìŒì„± ì±—ë´‡, ë‰´ìŠ¤ ê°ì„±ë¶„ì„")
    print("ğŸ¯ ML API: /ml/* ê²½ë¡œì—ì„œ ì œê³µ")
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''